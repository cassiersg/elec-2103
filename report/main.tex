\documentclass[english, DIV=13]{scrreprt}

\include{lib}

\title{LELEC2103}
\subtitle{Project in Electricity 3 : Electronic systems}
\author{Gaëtan Cassiers\and Antoine Paris}
\date{\today}

\begin{document}
\maketitle

\chapter{Introduction}

\chapter{Gameplay and features}
Our game is inspired by an existing game available on most smartphones and tablets
and developped by Ketchapp. Figure~\ref{fig:original-game} is a screenshot from this game.
In this original version of the game, the player (represented by the yellow cube on figure
~\ref{fig:original-game}) has to place itself correctly on the white structure in order
to fit in the hole of the wall coming in his direction at a constant speed. The objective
is to pass in as much wall as possible. Passing a wall gives 1 point, failing to pass a
wall makes the score starting back at 0.

Our version of the game differs from the original one in several aspects. First, this
is a two-players collaborative game. Second, a game only lasts a finite amount of time
and the two players can control the speed of the wall using the accelerometer.
Finally, failing to pass a wall only decreases the current score by 1.

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{img/original-game}
    \caption{Screenshot of the orginal game by Ketchapp.}
    \label{fig:original-game}
\end{figure}

\chapter{Network interface}
The way the two players communicate with each other is illustrated in figure~\ref{fig:
comm-scheme}. The approach taken here is client-server based. The server is responsible
for all the logic of the game and maintains an object representing the state of the game.
Centralizing computations in this way ensures a complete synchronization between clients.

A complete communication protocol was rigorously defined by the two groups. This
protocol defines an handshake procedure between a client and the server to ensure both
sides are ready before starting. Once the game has started, the two clients can send
messages to the server based on user inputs (accelerometer values, touch, or gesture).
The server then performs some computations on the game state such as computing player
positions, speed of the wall, remaining time, score, etc. Finally, the server
broadcasts the parts of the game state which changed.

On the practical side, one Raspberry-Pi runs both the server and a client while the other
one only runs a client.

\begin{figure}
    \centering
    \includegraphics[width=1.0\textwidth]{img/global_comm_scheme_cropped.pdf}
    \caption{Block diagram of the network communication.}
    \label{fig:comm-scheme}
\end{figure}

\chapter{Global view of the client system}
The global view of the client system is represented in figure~\ref{fig:global-desktop}
and figure~\ref{fig:global-device}. Through the network interface described in the
previous section, the client builds its own image of the game state. This client game
state is then fed to the rendering subsystem which produces a 3D image. This image
is then compressed and sent to the hardware interface.

One of the strength of our system is this hardware interface. This abstraction offers
a common layer to communicate both with a PC or a device. This eased a lot the development
process.

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{img/block_global_desktop_cropped.pdf}
    \caption{Block diagram of the client, when running on a PC.}
    \label{fig:global-desktop}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{img/block_global_device_cropped.pdf}
    \caption{Block diagram of the client, when running the raspberry-pi/DE0-Nano system.}
    \label{fig:global-device}
\end{figure}

\chapter{Rendering subsystem}

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{img/block_rendering_cropped.pdf}
    \caption{Pipeline for the rendering of the video.}
\end{figure}

\chapter{Compression subsystem}
\label{chap:compression}

\section{Goal}

The need for a compression system comes from the following observation:
when transferring 25 frames of 800x480 pixel, with 12 bits per pixel,
the bandwidth needed is \SI{115}{Mb/s}. The memory needed for each frame
is \SI{600}{kB}.

In our system, the SPI bandwidth available to transfer the video is \SI{5}{Mb/s},
and the memory available on the FPGA (onchip memory, SDRAM is used by the
nios/µC0S-II system) is \SI{30}{kB} per frame.

We neeed thus a compression of a factor larger than 20, that is such that
the video can be compressed in real-time. The decompression must be done
pixel per pixel, on-the-fly, since there is no memory available to store the
decompressed images.

\section{Principle}

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{img/compression_scheme_cropped.pdf}
    \caption{Principle view of the compression scheme.}
    \label{fig:compression}
\end{figure}

The compression system is based on three steps (see fig.~\ref{fig:compression}):
the color quantization, the run-length coding, and the Huffman coding. The first
step is lossy, while the two other steps are lossless.

\paragraph{Color quantization} The precision for each color channel is
reduced to 4 bits. This step is a preprocessing step that makes it possible
to implement and improves the efficiency of the following steps.

\paragraph{Run-length coding} The image, represented as a list of pixels,
is converted to a list of pairs $(\text{color}, \text{number of repetitions})$.
The allowed sizes for the number of repetitions are
$1, 2, 3, ..., 16,$ $32, 64, ..., 4096$. This allows to encode most images with
a number of blocks that is not too far from the optimum, while keeping the set
of number of repetitions small, which is required for the Huffman compression.

\paragraph{Huffman coding} Two Huffman trees are built: one for the pixels colors
and one for the numbers of repetitions. Each element of the pairs generated
at the previous stage is encoded with the corresponding Huffman tree.
All the codewords are then concatenated together to form the compressed image.

\section{Impact of the color quantization}

The color quantization has several goals. For the run-length coding,
the quantization creates chunks of constant color when there is a
continuous shading.\todo{Is it a correct wording ?} For the Huffman
coding, the reduction of the pixels coding from \SI{24}{bits} to
\SI{12}{bits} means the size of the colorspace is reduced from
\SI{16}{M} to \SI{4}{K}. This simplifies a lot the Huffman coding:
\begin{itemize}
    \item it is much easier to estimate the distribution of the colors
        to build the Huffman tree\footnote{
            The color and run-length distribution are estimated from a set of training
        images during at compile time.};
    \item it keeps the codewords length small, which simplifies the implementation:
        the memory bandwidth required is smaller;
    \item it reduces the amount of logic gates required to implement a decoder,
        which makes it possible to fit it on the FPGA;
    \item it also makes the software encoder faster, for the same reasons
        (memory bandwidth, code size)
\end{itemize}

The color quantization has an impact of the quality of the images,
but it is mainly visible when there is an area where there are
slightly different shades of the same color. For these kinds of images,
it may introduce a "staircase" effect. To avoid this artefact to be visible,
the rendering process has been tuned to avoid producing continuously varying colors,
through the choice of a adequated lightning scheme for the 3D scene (the lightning
has only the directionnal component of the phong lightning model).

\chapter{SPI slave subsystem}

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{img/spi_state_machine_cropped.pdf}
    \caption{State machine for the SPI communication protocol.}
\end{figure}

\chapter{Display management}

The system uses double buffering to avoid tearing in displayed images.
It is implemented by two RAMs on the FPGA (see fig.~\ref{fig:display-manager}).

The RAMs are connected to the decoder
(which decodes the code discussed in section~\ref{chap:compression})
through a MUX controlled by a \texttt{display control} register.

The RAMs are also connected to the SPI MMU. The write enable
signal of the RAMs are masked by the \texttt{display control} signal,
so that only RAM that is not connected to the decoder is written.

The \texttt{display control} register can be read from the SPI MMU,
and can be written by the SPI MMU, but only through a buffer register,
in order for changes of \texttt{display control} to be synchronized
to the \texttt{end of frame} signal from the display controller.
This synchronization system avoids tearing.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{img/display_manager_cropped.pdf}
    \caption{Block diagram of the display management and synchronization system.}
    \label{fig:display-manager}
\end{figure}

\chapter{Input detection subsystem}

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{img/tasks_mC_cropped.pdf}
    \caption{Tasks and their relationships on the uC/OS-II operating system.}
\end{figure}

\chapter{Player pictures acquisition}

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{img/block_pictures_cropped.pdf}
    \caption{Block diagram of the picture acquisition subsystem.}
\end{figure}

\chapter{Conclusion}

\end{document}
